```{r s4.init.datasets, echo = F, include = F}

load('../data/spain_geodata_temperature_1989_spring.RData')
load('../data/spain_preprocessed_data.RData')

validation.data <- sp_data_bin
sp_data_final_clean = sp_data_final_clean
sp_geo_data_clean = sp_geo_data_clean

sp_data_final_clean = sp_data_final_clean %>% dplyr::select(longitude,latitude,temp)

coordinates(sp_data_final_clean) <- ~ longitude + latitude

rm(sp_data, sp_data_bin, sp_data_final)
```

# Proceso de Krigging

Ahora que tenemos los elementos necesarios en nuestro análisis vamos a a pasar a estimar
nuevos valores basados en el modelo propuesto. Para ello vamos a considerar 2 casos:

* Una grilla generada dentro del dominio de nuestro dataset con una resolución de 0.2x0.2
en latitud y longitud. 
* Los puntos extraidos de la grilla del dataset inicial que utilizamos como _validación_
del modelo de krigging

## Modelos propuestos de krigging ordinario

Para nuestro dataset, debido a que observamos una dependencia clara entre nuestra variable
de interés (Temperatura promedio en superficie) y la métrica espacial, no podemos dar
por sentado que exista un modelo donde exista una media desconocida $\mu_0$ tal que nuestro
sistema se pueda describir como $Z(s)=\mu+\epsilon(s)$.

Dada la tendencia observada se propone un modelo de krigging universal de la forma:

$$
\left\{
    \begin{array}{rcl}
        Z(\mathbf{s}) & = & \mu(\mathbf{s})+\epsilon(\mathbf{s})\\
        \mu(\mathbf{s}) & = & \sum_{k}\beta_{k}f_{k}(\mathbf{s})
    \end{array}
\right. \,\text{,where }\mathbf{s}\in\mathbb{R}^2
$$

donde en nuestro caso consideraremos una tendencia lineal que modele nuestro sistema. A
partir de esto, considerando los dos modelos de variograma propuestos vamos a generar 
dos modelos de krigging y comparar sus resultados. Recordamos que los variogramas elegidos
son los siguientes:

| Modelo | Nugget | Sill | Range | $\kappa$ |
|:---:|:---:|:---:|:---:|:---:|
|`r as.character(vg.fit[2,]$model)` | 0 | `r vg.fit[2,]$psill` | `r vg.fit[2,]$range` | `r vg.fit[2,]$kappa` |
|`r as.character(vg.best.fit[2,]$model)` | 0 | `r vg.best.fit[2,]$psill` | `r vg.best.fit[2,]$range` | `r vg.best.fit[2,]$kappa` |

Previo a generar los modelos de krigging, debemos generar la grilla de predicción, como 
se dijo anteriormente tomaremos una grilla de tamaño 0.2x0.2 de esta manera estaremos
cubriendo puntos que los datos inicialmente no tenían. Para determinar la grilla, primero
obtenemos de nuestros datos los límites:

```{r s4.data.summary, echo = F}
summary(sp_geo_data_clean)
```

Dado que si tomamos los límites máximos del _summary_  estaríamos considerando datos fuera
de españa, con lo que vamos a definir un _boundary box_ de 1 punto menos en cada limite
obtenido.

```{r grid.def}
## Una vez seleccionados los modelos vamos a crear una grilla de predicción
## para ello vamos a tomar un sector interno del mapa de datos y vamos a analizar

g.lon.min = -8
g.lon.max = 1
g.lat.min = 37
g.lat.max = 42


grid.to.pred <- expand.grid(longitude = seq(g.lon.min, g.lon.max, by = 0.2),
                            latitude = seq(g.lat.min, g.lat.max, by	 = 0.2))
gridded(grid.to.pred) <-  ~ longitude + latitude
```

A partir de esta grilla, tenemos ahora `r length(grid.to.pred)` puntos a predecir con
nuestros modelos de krigging. Teniendo ya todo lo necesario podemos ajustar los modelos
correspondientes

```{r s4.krig.model, message = F}

trend <- formula(temp ~ longitude + latitude)

## Ahora que generamos la grilla vamos a hacer el cokrirgging

krig.fit <- krige(formula = trend,
                  locations = sp_data_final_clean,
                  newdata = grid.to.pred,
                  model = vg.fit,
                  debug.level = -1)

krig.alt.fit <- krige(formula = trend,
                      locations = sp_data_final_clean,
                      newdata = grid.to.pred,
                      model = vg.best.fit,
                      debug.level = -1)

validation.coords <- validation.data[,c(1,2)]

coordinates(validation.coords) <- ~ longitude + latitude

krig.val.data <- krige(formula = trend,
                       locations = sp_data_final_clean,
                       newdata = validation.coords,
                       model = vg.fit)

krig.val.data.alt <- krige(formula = trend,
                           locations = sp_data_final_clean,
                           newdata = validation.coords,
                           model = vg.best.fit)

```

## Resultados obtenidos

A partir de los modelos fiteados vamos a analizar las predicciones obtenidas sobre una 
grilla de predicción creada anteriormente y luego con los datos del test de validación.

### Grilla de predicción

A partir del krigging realizado sobre la grilla, obtenemos que nuestros datos predichos
tienen la siguiente distribución espacial:

```{r, echo = F, fig.cap = 'Resultados kriging universal para modelo Esférico', fig.align='center'}
polys = as(krig.fit,"SpatialPolygonsDataFrame")
polys_sf = as(polys, "sf")
points_sf = as(krig.fit, "sf")
dens.plot.1 <- ggplot(polys_sf) +
    geom_sf(aes(fill = var1.pred)) +
    ggtitle("Valores predichos [Sph]") +
    coord_sf(datum=st_crs(4326)) +
    scale_fill_viridis(option = "magma", direction = -1)
dens.plot.2 <- ggplot(polys_sf) +
    geom_sf(aes(fill = var1.var)) +
    ggtitle("Varianza de valores predichos [Sph]") +
    coord_sf(datum=st_crs(4326)) +
    scale_fill_viridis(option = "magma", direction = 1)

ggarrange(dens.plot.1,
          dens.plot.2,
          ncol = 1,
          nrow = 2)
```

Mientras que para segundo variograma propuesto

```{r, echo = F, fig.cap = 'Resultados kriging universal para modelo Matern', fig.align='center'}
polys = as(krig.alt.fit,"SpatialPolygonsDataFrame")
polys_sf = as(polys, "sf")
points_sf = as(krig.alt.fit, "sf")
dens.plot.1 <- ggplot(polys_sf) +
    geom_sf(aes(fill = var1.pred)) +
    ggtitle("Valores predichos [Matern]") +
    coord_sf(datum=st_crs(4326)) +
    scale_fill_viridis(option = "magma", direction = -1)
dens.plot.2 <- ggplot(polys_sf) +
    geom_sf(aes(fill = var1.var)) +
    ggtitle("Varianza de valores predichos [Matern]") +
    coord_sf(datum=st_crs(4326)) +
    scale_fill_viridis(option = "magma", direction = 1)

ggarrange(dens.plot.1,
          dens.plot.2,
          ncol = 1,
          nrow = 2)
```


### Datos de validación

Así también vamos a tomar los datos que separamos como *validación* y utilizamos el modelo
propuesto anteriormente para interpolar estos datos y compararlos con el dato inicial.

En la gráfica podemos ver que ambos modelos propuestos tienen una aproximación con una
varíanza respecto al valor observado pero que mantenemos una tendencia lineal.

```{r, echo = F, fig.cap = 'Datos observados versus datos interpolados por los modelos.', fig.align='center'}
val.data <- as.data.frame(cbind(validation.data$temp,
                                krig.val.data$var1.pred,
                                krig.val.data.alt$var1.pred))
names(val.data) <- c("original", "Spherical", "Matern")

fig.comp.val.1 <- val.data %>% melt(id.vars = "original") %>% ggplot() + 
    geom_point(aes(x = original,
                   y = value,
                   colour = as.factor(variable))) +
    geom_smooth(formula = y ~ x,
                method = lm,
                aes(x = original,
                    y = value,
                    colour = as.factor(variable),
                    fill = as.factor(variable)),
                show.legend = T) +
    scale_fill_discrete(name = "Model",
                        labels = c("Spherical", "Matern")) +
    labs(x = 'Valor original',
         y = 'Valor interpolado',
         colour = "Model")

fig.comp.val.1
```

A partir de estos valores podemos determinar además determinar los errores de
interpolación. Para esto vamos a considerar el RMSE

```{r, echo = F}
krig.err.1 <- sqrt(mean((validation.data$temp - krig.val.data$var1.pred)^2))
krig.err.2 <- sqrt(mean((validation.data$temp - krig.val.data.alt$var1.pred)^2))
```

| Modelo | RMSE |
|:---:|:---:|
|`r vg.fit$model` | `r krig.err.1`
|`r vg.best.fit$model` | `r krig.err.2`

## Validación del método

### Comparación con método de interpolación por K vecinos más cercanos

Anteriormente utilizamos krigging para poder interpolar los valores restantes en nuestra 
grilla, a partir de ello se genera un heatmap de las predicciones donde podemos ver el 
comportamiento de la variable de interés sobre nuestros nuevos puntos, por construcción
estaremos viendo puntos intermedios entre nuestro puntos iniciales que quizás no teníamos
suficiente información para asumir su valor. 

Por esto, proponemos evaluar primeramente el resultado obtenido si se hubiese utilizado
a KNN como método de interpolación de los datos. Veremos como se comporta el RMSE de este
método en función de la cantidad de vecinos a considerar en la interpolación.

```{r s4.knn.interpol, warning = F}
# K-nearest neighbours
# Cantidad de vecinos de 1 a 20 vecinos
k_vector = seq(1, 20)
k_error_vector = c()

## Calculamos el error RMSE de krigging
kriging_error = sqrt(mean((validation.data$temp - krig.val.data$var1.pred)^2))


for (k in k_vector){
    knn_model = knn.reg(sp_data_final_clean@coords,
                        test = NULL,
                        sp_data_final_clean$temp,
                        k = k)
    k_error = sqrt(mean((sp_data_final_clean$temp - knn_model$pred)^2))
    k_error_vector = c(k_error_vector, k_error)

}

knn.err <- data.frame(k = k_vector, rmse_knn = k_error_vector, rmse_krig = kriging_error)

knn.inter.fig <- knn.err %>% melt(id.vars = 'k') %>% ggplot(aes(x = k,
                                                                y = value,
                                                                colour = as.factor(variable))) +
    geom_line(size = 1) +
    labs( x = 'Cantidad de vecinos',
          y = 'RMSE de interpolación')

```

```{r, echo = F, fig.cap = "Error de interpolación vs #Vecinos", fig.align='center'}
knn.inter.fig
```

Del gráfico observamos que el error mínimo de interpolación lo obtenemos utilizando 4
vecinos para interpolar es de `r min(k_error_vector)`. Mientras que utilizando el método
de krigging obtenemos un RMSE de `r kriging_error`.

Con esto vemos que tenemos una mejora de casí 1 punto porcentual en el error respecto a la
máxima variabilidad de los datos presentados.

### K-fold cross validation

Para validar los modelos propuestos se realizó un cross validation en configuración de
_leave one out_ con lo que utilizamos 153 folds. 

```{r s4.krig.cv, message = F}
krig.cv1 <- krige.cv(formula = trend,
                     locations = sp_data_final_clean,
                     model = vg.fit,
                     nfold = 153)
krig.cv2 <- krige.cv(formula = trend,
                     locations = sp_data_final_clean,
                     model = vg.best.fit,
                     nfold = 153)
```


Los estadísticos obtenidos de esta cross validación se resumen en la siguiente tabla

| Estadístico | Krigging (Sph) | Krigging (Mat) |
| --- |:---:|:---:|
| MAE | `r mean(krig.cv1$residual)` | `r mean(krig.cv2$residual)` |
| RMSE | `r mean(krig.cv1$residual^2)` | `r mean(krig.cv2$residual^2)` |
| NRMSE | `r mean(krig.cv1$zscore^2)` | `r mean(krig.cv2$zscore^2)` |
| $\rho$ | `r cor(krig.cv1$observed, krig.cv1$observed - krig.cv1$residual)` | `r cor(krig.cv2$observed, krig.cv2$observed - krig.cv2$residual)` |

Además podemos visualizar el comportamiento de los datos observados y predichos, en este 
vemos hay una buena tendencia lineal entre los datos observados y los datos predichos.

```{r, echo = F, fig.cap = 'Comportamiento de los residuos obtenidos en el proceso de Cross validation.', fig.align='center'}
krig.cv.plot1 <- krig.cv1@data %>% ggplot(aes(x = observed, y = observed - residual)) +
    geom_point(colour = "turquoise3",
               shape = 15) +
    labs( x = "Observados (Sph)",
          y = "Predichos (Sph)") +
    geom_smooth(formula = y ~ x,
                method = lm,
                aes(x = observed,
                    y = observed - residual),
                show.legend = T,
                colour = "#cd0800",
                fill = "#eb9c99")

krig.cv.plot2 <- krig.cv2@data %>% ggplot(aes(x = observed, y = observed - residual)) +
    geom_point(colour = "turquoise3",
               shape = 15) +
    labs( x = "Observados (Mat)",
          y = "Predichos (Mat)") +
    geom_smooth(formula = y ~ x,
                method = lm,
                aes(x = observed,
                    y = observed - residual),
                show.legend = T,
                colour = "#cd0800",
                fill = "#eb9c99")

ggarrange(krig.cv.plot1,
          krig.cv.plot2,
          ncol = 2,
          nrow = 1)
```

A partir de esto analizamos y vemos que en ambas regresiones tenemos casi una pendiente 1.

```{r s4.reg.1}

r1 <- krig.cv1$observed - krig.cv1$residual
regresion1 <- lm(krig.cv1$observed ~ r1, data = krig.cv1)
summary(regresion1)
```

```{r s4.reg.2}
r2 <- krig.cv2$observed - krig.cv2$residual
regresion2 <- lm(krig.cv2$observed ~ r2, data = krig.cv2)
summary(regresion2)

```

Con esto vemos que ambos modelos propuestos nos ayudan a predecir con una precisión 
aceptable los datos faltantes en nuestro dataset.
